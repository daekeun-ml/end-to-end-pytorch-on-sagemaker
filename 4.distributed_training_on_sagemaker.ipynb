{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module 4. Distributed-Mutigpu Training with CutMix-ScriptMode\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API을 효과적으로 이용하기 위해 distributed-multigpu 학습을 위한 PyTorch 프레임워크 자체 구현만으로 모델 훈련을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time, datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 버전을 최신 버전으로 업데이트합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload dataset to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "# create a s3 bucket to hold data, note that your account might already created a bucket with the same name\n",
    "account_id = sess.client('sts').get_caller_identity()[\"Account\"]\n",
    "job_bucket = 'sagemaker-experiments-{}-{}'.format(sess.region_name, account_id)\n",
    "data_bucket = 'sagemaker-{}-{}'.format(sess.region_name, account_id)\n",
    "try:\n",
    "    if sess.region_name == \"us-east-1\":\n",
    "        sess.client('s3').create_bucket(Bucket=data_bucket)\n",
    "    else:\n",
    "        sess.client('s3').create_bucket(Bucket=data_bucket, \n",
    "                                        CreateBucketConfiguration={'LocationConstraint': sess.region_name})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "local_data_paths = glob.glob('./input/train_image_data_*.feather')\n",
    "s3_data_path = sagemaker.s3_input(s3_data='s3://{}/{}'.format(data_bucket, 'bangali/train'), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write main_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/requirements.txt\n",
    "albumentations\n",
    "pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/main_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/main_trainer.py\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import logging.handlers\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import dis_util\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker_containers\n",
    "import util\n",
    "## augmentation for setting\n",
    "from albumentations import (CLAHE, Blur, Compose, Flip, GaussNoise,\n",
    "                            GridDistortion, HorizontalFlip, HueSaturationValue,\n",
    "                            IAAAdditiveGaussianNoise, IAAEmboss,\n",
    "                            IAAPerspective, IAAPiecewiseAffine, IAASharpen,\n",
    "                            MedianBlur, MotionBlur, Normalize, OneOf,\n",
    "                            OpticalDistortion, RandomBrightnessContrast,\n",
    "                            RandomRotate90, Rotate, ShiftScaleRotate,\n",
    "                            Transpose)\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Apex import package\n",
    "try:\n",
    "    from apex.parallel import DistributedDataParallel as DDP\n",
    "    from apex.fp16_utils import *\n",
    "    from apex import amp, optimizers\n",
    "    from apex.multi_tensor_apply import multi_tensor_applier\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Please install apex from https://www.github.com/nvidia/apex to run this example.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def parser_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Default Setting\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--backend', type=str, default='nccl',\n",
    "                        help='backend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)')\n",
    "    parser.add_argument('--channels-last', type=bool, default=True)\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                        metavar='N', help='print frequency (default: 10)')\n",
    "\n",
    "    # Hyperparameter Setting\n",
    "    parser.add_argument('--model_name', type=str, default='resnet18')\n",
    "    parser.add_argument('--height', type=int, default=128)\n",
    "    parser.add_argument('--width', type=int, default=128)\n",
    "    parser.add_argument('--num_folds', type=int, default=5)\n",
    "    parser.add_argument('--vld_fold_idx', type=int, default=4)\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--num_epochs', type=int, default=3)\n",
    "    parser.add_argument('--batch-size', type=int, default=64)\n",
    "    parser.add_argument('--val-batch-size', type=int, default=200, metavar='N',\n",
    "                        help='input batch size for testing (default: 200)')\n",
    "\n",
    "    # APEX Setting for Distributed Training\n",
    "    parser.add_argument('--apex', type=bool, default=False)\n",
    "    parser.add_argument('--opt-level', type=str, default='O0')\n",
    "    parser.add_argument('--keep-batchnorm-fp32', type=str, default=None)\n",
    "    parser.add_argument('--loss-scale', type=str, default=None)\n",
    "    parser.add_argument('--sync_bn', action='store_false',\n",
    "                        help='enabling apex sync BN.')\n",
    "    parser.add_argument('--prof', default=-1, type=int,\n",
    "                        help='Only run 10 iterations for profiling.')\n",
    "\n",
    "    # SageMaker Container environment\n",
    "    parser.add_argument('--hosts', type=list,\n",
    "                        default=json.loads(os.environ['SM_HOSTS']))\n",
    "    parser.add_argument('--current-host', type=str,\n",
    "                        default=os.environ['SM_CURRENT_HOST'])\n",
    "    parser.add_argument('--model-dir', type=str,\n",
    "                        default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--data-dir', type=str,\n",
    "                        default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    parser.add_argument('--num-gpus', type=int,\n",
    "                        default=os.environ['SM_NUM_GPUS'])\n",
    "    parser.add_argument('--output_data_dir', type=str,\n",
    "                        default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "    \n",
    "    \n",
    "class BangaliDataset(Dataset):\n",
    "    def __init__(self, imgs, label_df=None, transform=None):\n",
    "        self.imgs = imgs\n",
    "        self.label_df = label_df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_idx = self.label_df.iloc[idx].id\n",
    "        img = (self.imgs[img_idx]).astype(np.uint8)\n",
    "        img = 255 - img\n",
    "    \n",
    "        img = img[:,:,np.newaxis]\n",
    "        img = np.repeat(img, 3, axis=2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)['image']        \n",
    "        \n",
    "        if self.label_df is not None:\n",
    "            label_1 = self.label_df.iloc[idx].grapheme_root\n",
    "            label_2 = self.label_df.iloc[idx].vowel_diacritic\n",
    "            label_3 = self.label_df.iloc[idx].consonant_diacritic           \n",
    "            return img, np.array([label_1, label_2, label_3])        \n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "        \n",
    "\n",
    "def _rand_bbox(size, lam):\n",
    "    '''\n",
    "    CutMix Helper function.\n",
    "    Retrieved from https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py\n",
    "    '''\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    # 폭과 높이는 주어진 이미지의 폭과 높이의 beta distribution에서 뽑은 lambda로 얻는다\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    \n",
    "    # patch size 의 w, h 는 original image 의 w,h 에 np.sqrt(1-lambda) 를 곱해준 값입니다.\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # patch의 중심점은 uniform하게 뽑힘\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def _set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def _get_images(args, data_type='train'):\n",
    "\n",
    "    logger.info(\"=== Getting Labels ===\")\n",
    "    logger.info(args.data_dir)\n",
    "    \n",
    "    label_df = pd.read_csv(os.path.join(args.data_dir, 'train_folds.csv'))\n",
    "     \n",
    "    trn_fold = [i for i in range(args.num_folds) if i not in [args.vld_fold_idx]]\n",
    "    vld_fold = [args.vld_fold_idx]\n",
    "\n",
    "    trn_idx = label_df.loc[label_df['fold'].isin(trn_fold)].index\n",
    "    vld_idx = label_df.loc[label_df['fold'].isin(vld_fold)].index\n",
    "\n",
    "    logger.info(\"=== Getting Images ===\")\n",
    "    # files = [file for file in glob.glob(os.path.join(args.data_dir,'*')) if file.split('.')[-1] == 'parquet']\n",
    "    files = [f'{args.data_dir}/{data_type}_image_data_{i}.feather' for i in range(4)]\n",
    "    logger.info(files)\n",
    "    \n",
    "    image_df_list = [pd.read_feather(f) for f in files]\n",
    "    imgs = [df.iloc[:, 1:].values.reshape(-1, args.height, args.width) for df in image_df_list]\n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    args.imgs = np.concatenate(imgs, axis=0)\n",
    "    \n",
    "    args.trn_df = label_df.loc[trn_idx]\n",
    "    args.vld_df = label_df.loc[vld_idx]\n",
    "    \n",
    "    return args \n",
    "\n",
    "\n",
    "def _get_train_data_loader(args, **kwargs):\n",
    "    logger.info(\"Get train data loader\")\n",
    "    train_transforms = Compose([\n",
    "        Rotate(20),\n",
    "            OneOf([\n",
    "                IAAAdditiveGaussianNoise(),\n",
    "                GaussNoise(),\n",
    "            ], p=0.2),\n",
    "            OneOf([\n",
    "                MotionBlur(p=.2),\n",
    "                MedianBlur(blur_limit=3, p=0.1),\n",
    "                Blur(blur_limit=3, p=0.1),\n",
    "            ], p=0.2),\n",
    "            ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "            OneOf([\n",
    "                OpticalDistortion(p=0.3),\n",
    "                GridDistortion(p=.1),\n",
    "                IAAPiecewiseAffine(p=0.3),\n",
    "            ], p=0.2),\n",
    "            OneOf([\n",
    "                CLAHE(clip_limit=2),\n",
    "                IAASharpen(),\n",
    "                IAAEmboss(),\n",
    "                RandomBrightnessContrast(),            \n",
    "            ], p=0.3),\n",
    "            HueSaturationValue(p=0.3),\n",
    "        Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "        ], p=1.0)\n",
    "    \n",
    "    dataset = BangaliDataset(imgs=args.imgs, label_df=args.trn_df, transform=train_transforms)\n",
    "    train_sampler = data.distributed.DistributedSampler(\n",
    "        dataset, num_replicas=int(args.world_size), rank=int(args.rank)) if args.multigpus_distributed else None\n",
    "    return data.DataLoader(dataset, batch_size=args.batch_size, shuffle=train_sampler is None,\n",
    "                                       sampler=train_sampler, **kwargs), train_sampler\n",
    "\n",
    "\n",
    "def _get_val_data_loader(args, **kwargs):\n",
    "    logger.info(\"Get val data loader\")   \n",
    "    \n",
    "    val_transforms = Compose([\n",
    "        Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    dataset = BangaliDataset(imgs=args.imgs, label_df=args.vld_df, transform=val_transforms)\n",
    "    val_sampler = data.distributed.DistributedSampler(dataset) if args.multigpus_distributed else None\n",
    "    return data.DataLoader(dataset, batch_size=args.val_batch_size, shuffle=False, \n",
    "                           sampler=val_sampler, **kwargs)\n",
    "\n",
    "def train(current_gpu, args):\n",
    "    \n",
    "    _set_seed()\n",
    "    \n",
    "    best_acc1 = -1\n",
    "    model_history = {}\n",
    "    model_history = util.init_modelhistory(model_history)\n",
    "    train_start = time.time()\n",
    "\n",
    "    ## choose model from pytorch model_zoo\n",
    "    model = util.torch_model(args.model_name, pretrained=True)\n",
    "    last_hidden_units = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(last_hidden_units, 186)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    ## distributed_setting \n",
    "    model, args = dis_util.dist_setting(current_gpu, model, args)\n",
    "\n",
    "    ## CuDNN library will benchmark several algorithms and pick that which it found to be fastest\n",
    "    cudnn.benchmark = False if args.seed else True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr) \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                          verbose=True, patience=5, \n",
    "                                                          factor=0.5)\n",
    "    if args.apex:\n",
    "        model, optimizer = dis_util.apex_init(model, optimizer, args)\n",
    "   \n",
    "    args = _get_images(args, data_type='train')\n",
    "    train_loader, train_sampler = _get_train_data_loader(args, **args.kwargs)\n",
    "    val_loader = _get_val_data_loader(args, **args.kwargs)\n",
    "\n",
    "    logger.info(\"Processes {}/{} ({:.0f}%) of train data\".format(\n",
    "        len(train_loader.sampler), len(train_loader.dataset),\n",
    "        100. * len(train_loader.sampler) / len(train_loader.dataset)\n",
    "    ))\n",
    "\n",
    "    logger.info(\"Processes {}/{} ({:.0f}%) of test data\".format(\n",
    "        len(val_loader.sampler), len(val_loader.dataset),\n",
    "        100. * len(val_loader.sampler) / len(val_loader.dataset)\n",
    "    ))\n",
    "\n",
    "    for epoch in range(1, args.num_epochs + 1):\n",
    "        batch_time = util.AverageMeter('Time', ':6.3f')\n",
    "        data_time = util.AverageMeter('Data', ':6.3f')\n",
    "        losses = util.AverageMeter('Loss', ':.4e')\n",
    "        top1 = util.AverageMeter('Acc@1', ':6.2f')\n",
    "        top5 = util.AverageMeter('Acc@5', ':6.2f')\n",
    "        progress = util.ProgressMeter(\n",
    "            len(train_loader),\n",
    "            [batch_time, data_time, losses, top1, top5],\n",
    "            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "        \n",
    "        trn_loss = []\n",
    "        model.train()\n",
    "        end = time.time()\n",
    "        running_loss = 0.0\n",
    "        ## Set epoch count for DistributedSampler\n",
    "        if args.multigpus_distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "            \n",
    "        for batch_idx, (input, target) in enumerate((train_loader)):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "            batch_idx += 1\n",
    "\n",
    "            ##### DATA Processing #####\n",
    "            targets_gra = target[:, 0]\n",
    "            targets_vow = target[:, 1]\n",
    "            targets_con = target[:, 2]\n",
    "\n",
    "            # 50%의 확률로 원본 데이터 그대로 사용    \n",
    "            if np.random.rand() < 0.5:\n",
    "                \n",
    "                logits = model(input)\n",
    "                grapheme = logits[:,:168]\n",
    "                vowel = logits[:, 168:179]\n",
    "                cons = logits[:, 179:]\n",
    "            \n",
    "                loss1 = loss_fn(grapheme, targets_gra)\n",
    "                loss2 = loss_fn(vowel, targets_vow)\n",
    "                loss3 = loss_fn(cons, targets_con) \n",
    "            else:\n",
    "                lam = np.random.beta(1.0, 1.0) \n",
    "                rand_index = torch.randperm(input.size()[0])\n",
    "                shuffled_targets_gra = targets_gra[rand_index]\n",
    "                shuffled_targets_vow = targets_vow[rand_index]\n",
    "                shuffled_targets_con = targets_con[rand_index]\n",
    "\n",
    "                bbx1, bby1, bbx2, bby2 = _rand_bbox(input.size(), lam)\n",
    "                input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # 픽셀 비율과 정확히 일치하도록 lambda 파라메터 조정  \n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
    "\n",
    "                logits = model(input)\n",
    "                grapheme = logits[:,:168]\n",
    "                vowel = logits[:, 168:179]\n",
    "                cons = logits[:, 179:]\n",
    "            \n",
    "                loss1 = loss_fn(grapheme, targets_gra) * lam + loss_fn(grapheme, shuffled_targets_gra) * (1. - lam)\n",
    "                loss2 = loss_fn(vowel, targets_vow) * lam + loss_fn(vowel, shuffled_targets_vow) * (1. - lam)\n",
    "                loss3 = loss_fn(cons, targets_con) * lam + loss_fn(cons, shuffled_targets_con) * (1. - lam)\n",
    "\n",
    "            loss = 0.5 * loss1 + 0.25 * loss2 + 0.25 * loss3    \n",
    "            trn_loss.append(loss.item())\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            #########################################################\n",
    "            optimizer.zero_grad()         \n",
    "            if args.apex:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            # Printing vital information\n",
    "            if (batch_idx) % (args.log_interval) == 0:\n",
    "                s = f'[Epoch {epoch} Batch {batch_idx}/{len(train_loader)}] ' \\\n",
    "                f'loss: {running_loss / args.log_interval:.4f}'\n",
    "                print(s)\n",
    "                running_loss = 0 \n",
    "                # Every log_interval iterations, check the loss, accuracy, and speed.\n",
    "                # For best performance, it doesn't make sense to print these metrics every\n",
    "                # iteration, since they incur an allreduce and some host<->device syncs.\n",
    "\n",
    "                # Measure accuracy\n",
    "                prec1, prec5 = util.accuracy(logits, target, topk=(1, 5))\n",
    "\n",
    "                # Average loss and accuracy across processes for logging\n",
    "                if args.multigpus_distributed:\n",
    "                    reduced_loss = dis_util.reduce_tensor(loss.data, args)\n",
    "                    prec1 = dis_util.reduce_tensor(prec1, args)\n",
    "                    prec5 = dis_util.reduce_tensor(prec5, args)\n",
    "                else:\n",
    "                    reduced_loss = loss.data\n",
    "                \n",
    "                # to_python_float incurs a host<->device sync\n",
    "                losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "                top1.update(to_python_float(prec1), input.size(0))\n",
    "                top5.update(to_python_float(prec5), input.size(0))\n",
    "                \n",
    "                ## Waiting until finishing operations on GPU (Pytorch default: async)\n",
    "                torch.cuda.synchronize()\n",
    "                batch_time.update((time.time() - end)/args.log_interval)\n",
    "                end = time.time()\n",
    "\n",
    "                if current_gpu == 0:\n",
    "                    print('Epoch: [{0}][{1}/{2}]  '\n",
    "                          'Time {batch_time.val:.3f} ({batch_time.avg:.3f})  '\n",
    "                          'Speed {3:.3f} ({4:.3f})  '\n",
    "                          'Loss {loss.val:.10f} ({loss.avg:.4f})  '\n",
    "                          'Prec@1 {top1.val:.3f} ({top1.avg:.3f})  '\n",
    "                          'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                              epoch, batch_idx, len(train_loader),\n",
    "                              args.world_size*args.batch_size/batch_time.val,\n",
    "                              args.world_size*args.batch_size/batch_time.avg,\n",
    "                              batch_time=batch_time,\n",
    "                              loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "        if current_gpu == 0:\n",
    "            model_history['epoch'].append(epoch)\n",
    "            model_history['batch_idx'].append(batch_idx)\n",
    "            model_history['batch_time'].append(batch_time.val)\n",
    "            model_history['losses'].append(losses.val)\n",
    "            model_history['top1'].append(top1.val)\n",
    "            model_history['top5'].append(top5.val)\n",
    "        \n",
    "        \n",
    "        acc1 = validate(val_loader, model, loss_fn, epoch, model_history, trn_loss, args)            \n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "        \n",
    "        if not args.multigpus_distributed or (args.multigpus_distributed and args.rank % args.num_gpus == 0):\n",
    "            util.save_history(os.path.join(args.output_data_dir,\n",
    "                          'model_history.p'), model_history)\n",
    "\n",
    "            util.save_model({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_name': args.model_name,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_acc1': best_acc1,\n",
    "                'optimizer': optimizer.state_dict()\n",
    "            }, is_best, args.model_dir)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, loss_fn, epoch, model_history, trn_loss, args):\n",
    "    batch_time = util.AverageMeter('Time', ':6.3f')\n",
    "    losses = util.AverageMeter('Loss', ':.4e')\n",
    "    top1 = util.AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = util.AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = util.ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "    val_loss = []\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "    \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "  \n",
    "\n",
    "    for batch_idx, (input, target) in enumerate((val_loader)):\n",
    "        batch_idx += 1\n",
    "        with torch.no_grad():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "        \n",
    "            logits = model(input)\n",
    "            grapheme = logits[:,:168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "\n",
    "            loss= 0.5* loss_fn(grapheme, target[:,0]) + 0.25*loss_fn(vowel, target[:,1]) + \\\n",
    "            0.25*loss_fn(vowel, target[:,2])\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            grapheme = grapheme.cpu().argmax(dim=1).data.numpy()\n",
    "            vowel = vowel.cpu().argmax(dim=1).data.numpy()\n",
    "            cons = cons.cpu().argmax(dim=1).data.numpy()\n",
    "\n",
    "            val_true.append(target.cpu().numpy())\n",
    "            val_pred.append(np.stack([grapheme, vowel, cons], axis=1))                \n",
    "  \n",
    "                \n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = util.accuracy(logits, target, topk=(1, 5))\n",
    "\n",
    "        if args.multigpus_distributed:\n",
    "            reduced_loss = dis_util.reduce_tensor(loss.data, args)\n",
    "            prec1 = dis_util.reduce_tensor(prec1, args)\n",
    "            prec5 = dis_util.reduce_tensor(prec5, args)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), input.size(0))\n",
    "        top1.update(to_python_float(prec1), input.size(0))\n",
    "        top5.update(to_python_float(prec5), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # TODO:  Change timings to mirror train().\n",
    "        if args.current_gpu == 0 and batch_idx % args.log_interval == 0:\n",
    "            print('Test: [{0}/{1}]  '\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})  '\n",
    "                  'Speed {2:.3f} ({3:.3f})  '\n",
    "                  'val_Loss {loss.val:.4f} ({loss.avg:.4f})  '\n",
    "                  'val_Prec {top1.val:.3f} ({top1.avg:.3f})  '\n",
    "                  'val_Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      batch_idx, len(val_loader),\n",
    "                      args.world_size * args.batch_size / batch_time.val,\n",
    "                      args.world_size * args.batch_size / batch_time.avg,\n",
    "                      batch_time=batch_time, loss=losses,\n",
    "                      top1=top1, top5=top5))\n",
    "            model_history['val_epoch'].append(epoch)\n",
    "            model_history['val_batch_idx'].append(batch_idx)\n",
    "            model_history['val_batch_time'].append(batch_time.val)\n",
    "            model_history['val_losses'].append(losses.val)\n",
    "            model_history['val_top1'].append(top1.val)\n",
    "            model_history['val_top5'].append(top5.val)\n",
    "\n",
    "\n",
    "\n",
    "    val_true_concat = np.concatenate(val_true)\n",
    "    val_pred_concat = np.concatenate(val_pred)\n",
    "    val_loss_mean = np.mean(val_loss)\n",
    "    trn_loss_mean = np.mean(trn_loss)\n",
    "  \n",
    "\n",
    "    score_g = recall_score(val_true_concat[:,0], val_pred_concat[:,0], average='macro')\n",
    "    score_v = recall_score(val_true_concat[:,1], val_pred_concat[:,1], average='macro')\n",
    "    score_c = recall_score(val_true_concat[:,2], val_pred_concat[:,2], average='macro')\n",
    "    final_score = np.average([score_g, score_v, score_c], weights=[2,1,1])\n",
    "\n",
    "    if args.current_gpu == 0:\n",
    "        # Printing vital information\n",
    "        s = f'[Epoch {epoch}] ' \\\n",
    "        f'trn_loss: {trn_loss_mean:.4f}, vld_loss: {val_loss_mean:.4f}, score: {final_score:.4f}, ' \\\n",
    "        f'score_g: {score_g:.4f}, score_v:{score_v:.4f}, score_c: {score_c:.4f}'          \n",
    "        print(s)  \n",
    "        \n",
    "        \n",
    "    print('  Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    model_history['val_avg_epoch'].append(epoch)\n",
    "    model_history['val_avg_batch_time'].append(batch_time.avg)\n",
    "    model_history['val_avg_losses'].append(losses.avg)\n",
    "    model_history['val_avg_top1'].append(top1.avg)\n",
    "    model_history['val_avg_top5'].append(top5.avg)\n",
    "    return final_score\n",
    "\n",
    "## iter() overflowerror: cannot serialize a bytes object larger than 4 gib --> num_worker=0 resolved\n",
    "def main():\n",
    "    args = parser_args()\n",
    "    args.use_cuda = args.num_gpus > 0\n",
    "    print(\"args.use_cuda : {} , args.num_gpus : {}\".format(\n",
    "        args.use_cuda, args.num_gpus))\n",
    "    args.kwargs = {'num_workers': 0,\n",
    "                   'pin_memory': True} if args.use_cuda else {}\n",
    "    args.device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")  \n",
    "    \n",
    "    print(\"main args : {}\".format(args))\n",
    "\n",
    "    dis_util.dist_init(train, args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/dis_util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/dis_util.py\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "import sagemaker_containers\n",
    "\n",
    "try:\n",
    "    from apex.parallel import DistributedDataParallel as DDP\n",
    "    from apex.fp16_utils import *\n",
    "    from apex import amp, optimizers\n",
    "    from apex.multi_tensor_apply import multi_tensor_applier\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Please install apex from https://www.github.com/nvidia/apex to run this example.\")\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def dist_init(fn, args):\n",
    "    \n",
    "    \n",
    "    print(\"dist_init args : {}\".format(args))\n",
    "    \n",
    "    \n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    args.is_distributed = len(args.hosts) > 1 and args.backend is not None\n",
    "    args.is_multigpus = args.num_gpus > 1\n",
    "    args.multigpus_distributed = (args.is_distributed or args.is_multigpus)\n",
    "\n",
    "    logger.debug(\"Distributed training - {}\".format(args.is_distributed))\n",
    "    logger.debug(\"Number of gpus available - {}\".format(args.num_gpus))\n",
    "\n",
    "    args.world_size = 1\n",
    "    if args.multigpus_distributed:\n",
    "        # Initialize the distributed environment.\n",
    "        args.apex = True\n",
    "        args.world_size = len(args.hosts) * args.num_gpus\n",
    "        os.environ['WORLD_SIZE'] = str(args.world_size)\n",
    "        args.host_num = args.hosts.index(args.current_host)\n",
    "        mp.spawn(fn, nprocs=args.num_gpus, args=(args,))\n",
    "    else:\n",
    "        current_gpu = 0\n",
    "        fn(current_gpu, args)\n",
    "\n",
    "\n",
    "def dist_setting(current_gpu, model, args):\n",
    "    print(\"channels_last : {}\".format(args.channels_last))\n",
    "    if args.channels_last:\n",
    "        args.memory_format = torch.channels_last\n",
    "    else:\n",
    "        args.memory_format = torch.contiguous_format\n",
    "\n",
    "    if args.apex:\n",
    "        args.lr = args.lr*float(args.world_size)\n",
    "        \n",
    "    args.current_gpu = current_gpu\n",
    "    if args.current_gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.current_gpu))\n",
    "\n",
    "    if args.multigpus_distributed:\n",
    "        args.rank = args.num_gpus * args.host_num + args.current_gpu\n",
    "        dist.init_process_group(backend=args.backend,\n",
    "                                rank=args.rank, world_size=args.world_size)\n",
    "        logger.info('Initialized the distributed environment: \\'{}\\' backend on {} nodes. '.format(\n",
    "            args.backend, dist.get_world_size()) + 'Current host rank is {}. Number of gpus: {}'.format(\n",
    "            dist.get_rank(), args.num_gpus))\n",
    "\n",
    "    if args.sync_bn:\n",
    "        import apex\n",
    "        print(\"using apex synced BN\")\n",
    "        model = apex.parallel.convert_syncbn_model(model)\n",
    "\n",
    "    if args.multigpus_distributed:\n",
    "        if args.current_gpu is not None:\n",
    "            torch.cuda.set_device(args.current_gpu)\n",
    "            args.batch_size = int(args.batch_size / args.num_gpus)\n",
    "            if not args.apex:\n",
    "                model.cuda(args.current_gpu)\n",
    "                model = torch.nn.parallel.DistributedDataParallel(\n",
    "                    model, device_ids=[args.current_gpu])\n",
    "        else:\n",
    "            if not args.apex:\n",
    "                model.cuda()\n",
    "                model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.current_gpu is not None:\n",
    "        torch.cuda.set_device(args.current_gpu)\n",
    "        if not args.apex:\n",
    "            model = model.cuda(args.current_gpu)\n",
    "    else:\n",
    "        if not args.apex:\n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    return model, args\n",
    "\n",
    "\n",
    "def apex_init(model, optimizer, args):\n",
    "    model = model.cuda().to(memory_format=args.memory_format)\n",
    "    model, optimizer = amp.initialize(model, optimizer,\n",
    "                                      opt_level=args.opt_level,\n",
    "                                      keep_batchnorm_fp32=args.keep_batchnorm_fp32,\n",
    "                                      loss_scale=args.loss_scale\n",
    "                                      )\n",
    "    if args.multigpus_distributed:\n",
    "        model = DDP(model, delay_allreduce=True)\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor, args):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/util.py\n",
    "\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.distributed\n",
    "from torchvision import models\n",
    "\n",
    "import sagemaker_containers\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def torch_model(model_name, pretrained=True):\n",
    "    model_names = sorted(name for name in models.__dict__\n",
    "                         if name.islower() and not name.startswith(\"__\")\n",
    "                         and callable(models.__dict__[name]))\n",
    "\n",
    "    if(model_name == \"inception_v3\"):\n",
    "        raise RuntimeError(\n",
    "            \"Currently, inception_v3 is not supported by this example.\")\n",
    "\n",
    "    # create model\n",
    "    if pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(model_name))\n",
    "        model = models.__dict__[model_name](pretrained=True)\n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(model_name))\n",
    "        model = models.__dict__[model_name]()\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(logits, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "#         print(\"batch_size : {}\".format(batch_size))\n",
    "\n",
    "        _, pred1 = logits[:, :168].topk(maxk, 1, True, True)\n",
    "        _, pred2 = logits[:, 168:179].topk(maxk, 1, True, True)\n",
    "        _, pred3 = logits[:, 179:].topk(maxk, 1, True, True)\n",
    "\n",
    "#         print(\"pred1 : {}, pred2 : {}, pred3 : {}\".format(pred1 ,pred2, pred3))\n",
    "        pred1 = pred1.t()\n",
    "        pred2 = pred2.t()\n",
    "        pred3 = pred3.t()\n",
    "        correct1 = pred1.eq(target[:,0].view(1, -1).expand_as(pred1))\n",
    "        correct2 = pred2.eq(target[:,1].view(1, -1).expand_as(pred2))\n",
    "        correct3 = pred3.eq(target[:,2].view(1, -1).expand_as(pred3))\n",
    "#         print(\"correct1 : {}, correct2 : {}, correct3 : {}\".format(correct1 ,correct2, correct3))\n",
    "        \n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k1 = correct1[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            correct_k2 = correct2[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            correct_k3 = correct3[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            correct_k = 0.5 * correct_k1 + 0.25 * correct_k2 + 0.25 * correct_k3\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res    \n",
    "    \n",
    "\n",
    "def save_model(state, is_best, model_dir):\n",
    "    logger.info(\"Saving the model.\")\n",
    "    filename = os.path.join(model_dir, 'checkpoint.pth')\n",
    "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, os.path.join(model_dir, 'model_best.pth'))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "        \n",
    "def adjust_learning_rate(optimizer, epoch, step, len_epoch, args):\n",
    "    \"\"\"LR schedule that should yield 76% converged accuracy with batch size 256\"\"\"\n",
    "    factor = epoch // 5\n",
    "\n",
    "    if epoch >= 10:\n",
    "        factor = factor + 1\n",
    "\n",
    "    lr = args.lr*(0.1**factor)\n",
    "\n",
    "    \"\"\"Warmup\"\"\"\n",
    "    if epoch < 3:\n",
    "        lr = lr*float(1 + step + epoch*len_epoch)/(3.*len_epoch)\n",
    "\n",
    "    if(args.current_gpu == 0):\n",
    "        print(\"epoch = {}, step = {}, lr = {}\".format(epoch, step, lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def save_history(path, history):\n",
    "\n",
    "    history_for_json = {}\n",
    "    # transform float values that aren't json-serializable\n",
    "    for key in history.keys():\n",
    "        history_for_json[key] = list(map(float, history[key]))\n",
    "\n",
    "    with codecs.open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(history_for_json, f, separators=(\n",
    "            ',', ':'), sort_keys=True, indent=4)\n",
    "        \n",
    "        \n",
    "\n",
    "def init_modelhistory(model_history):\n",
    "    model_history['epoch'] = []\n",
    "    model_history['batch_idx'] = []\n",
    "    model_history['batch_time'] = []\n",
    "    model_history['losses'] = []\n",
    "    model_history['top1'] = []\n",
    "    model_history['top5'] = []\n",
    "    model_history['val_epoch'] = []\n",
    "    model_history['val_batch_idx'] = []\n",
    "    model_history['val_batch_time'] = []\n",
    "    model_history['val_losses'] = []\n",
    "    model_history['val_top1'] = []\n",
    "    model_history['val_top5'] = []\n",
    "    model_history['val_avg_epoch'] = []\n",
    "    model_history['val_avg_batch_time'] = []\n",
    "    model_history['val_avg_losses'] = []\n",
    "    model_history['val_avg_top1'] = []\n",
    "    model_history['val_avg_top5'] = []\n",
    "    return model_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:Prec@1', 'Regex': 'Prec@1: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:trn_loss', 'Regex': 'trn_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:vld_loss', 'Regex': 'vld_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:score_g', 'Regex': 'score_g: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:score_v', 'Regex': 'score_v: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:score_c', 'Regex': 'score_c: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:Prec', 'Regex': 'val_Prec: ([0-9\\\\.]+)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'model_name' : 'resnet18',\n",
    "        'height' : 137,\n",
    "        'width' : 236,\n",
    "        'num_epochs': 5,\n",
    "        'batch-size' : 256*4,   ## 192 for 8xlarge*2, 100 for 16xlarge*2, 64 for 16xlarge*3\n",
    "        'backend': 'nccl',\n",
    "        'lr': 0.0001,  ## 0.01. 0.003\n",
    "        'opt-level' : 'O0'\n",
    "    }\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.p3.8xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='./main_trainer.py',\n",
    "    source_dir='./src',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker.Session(sagemaker_client=sm),\n",
    "    framework_version='1.5.0',\n",
    "    train_instance_count=train_instance_count,\n",
    "    train_instance_type=train_instance_type,\n",
    "    train_volume_size=400,\n",
    "    hyperparameters=hyperparameters,\n",
    "#     train_use_spot_instances=True,  # spot instance 활용\n",
    "#     train_max_run=12*60*60,\n",
    "#     train_max_wait=12*60*60,\n",
    "#     checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "#     tensorboard_output_config=TensorBoardOutputConfig(tensorboard_output),\n",
    "    metric_definitions=metrics_definitions,\n",
    "    enable_sagemaker_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "training_job_name = \"training-job-{}\".format(int(time.time()))\n",
    "\n",
    "# Now associate the estimator with the Experiment and Trial\n",
    "estimator.fit(\n",
    "    inputs=s3_data_path, \n",
    "    job_name=training_job_name,\n",
    "    logs='All',\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-20 15:25:49 Starting - Starting the training job...\n",
      "2020-08-20 15:25:51 Starting - Launching requested ML instances......\n",
      "2020-08-20 15:26:56 Starting - Preparing the instances for training............\n",
      "2020-08-20 15:28:51 Downloading - Downloading input data......\n",
      "2020-08-20 15:30:03 Training - Downloading the training image.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:24,959 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:25,003 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:25,007 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:25,398 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:25,399 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:25,399 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:25,399 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp4xv4gwdd/module_dir\u001b[0m\n",
      "\u001b[34mCollecting albumentations\n",
      "  Downloading albumentations-0.4.6.tar.gz (117 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow\n",
      "  Downloading pyarrow-1.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from albumentations->-r requirements.txt (line 1)) (1.16.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from albumentations->-r requirements.txt (line 1)) (1.2.2)\u001b[0m\n",
      "\u001b[34mCollecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from albumentations->-r requirements.txt (line 1)) (5.3.1)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.4.0.42-cp36-cp36m-manylinux2014_x86_64.whl (36.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (7.1.0)\u001b[0m\n",
      "\u001b[34mCollecting imageio\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting Shapely\n",
      "  Downloading Shapely-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (1.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (1.14.0)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.42-cp36-cp36m-manylinux2014_x86_64.whl (49.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting scikit-image>=0.14.2\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (3.2.1)\u001b[0m\n",
      "\u001b[34mCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.8.13-py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (2.4)\u001b[0m\n",
      "\u001b[34mCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations->-r requirements.txt (line 1)) (4.4.2)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: albumentations, default-user-module-name\n",
      "  Building wheel for albumentations (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for albumentations (setup.py): finished with status 'done'\n",
      "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65167 sha256=513cddd7582afb71691ac0d62b98e65e035cabdfd8f15fa392a4bf356f5c6cde\n",
      "  Stored in directory: /root/.cache/pip/wheels/38/db/df/d6cb0be184075a7799c1fd79240c389c16f51dfe18dc3332fa\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=38601 sha256=df91a1e9b4f604511d91119bad685f88c8ee3fdca557e6df9952886386c06d65\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mh_aaudg/wheels/fb/4b/61/a5c4bdfb8730c3398aee33cd3c7dc563581cdec6f205788ace\u001b[0m\n",
      "\u001b[34mSuccessfully built albumentations default-user-module-name\u001b[0m\n",
      "\u001b[34mERROR: scikit-image 0.17.2 has requirement pillow!=7.1.0,!=7.1.1,>=4.3.0, but you'll have pillow 7.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mInstalling collected packages: imageio, Shapely, opencv-python, tifffile, PyWavelets, scikit-image, imgaug, opencv-python-headless, albumentations, pyarrow, default-user-module-name\u001b[0m\n",
      "\n",
      "2020-08-20 15:30:23 Training - Training image download completed. Training in progress.\u001b[34mSuccessfully installed PyWavelets-1.1.1 Shapely-1.7.0 albumentations-0.4.6 default-user-module-name-1.0.0 imageio-2.9.0 imgaug-0.4.0 opencv-python-4.4.0.42 opencv-python-headless-4.4.0.42 pyarrow-1.0.0 scikit-image-0.17.2 tifffile-2020.8.13\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.1; however, version 20.2.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-20 15:30:41,310 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"opt-level\": \"O0\",\n",
      "        \"lr\": 0.0001,\n",
      "        \"batch-size\": 1024,\n",
      "        \"model_name\": \"resnet18\",\n",
      "        \"width\": 236,\n",
      "        \"backend\": \"nccl\",\n",
      "        \"num_epochs\": 5,\n",
      "        \"height\": 137\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"training-job-1597937149\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-322537213286/training-job-1597937149/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"./main_trainer\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"./main_trainer.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"nccl\",\"batch-size\":1024,\"height\":137,\"lr\":0.0001,\"model_name\":\"resnet18\",\"num_epochs\":5,\"opt-level\":\"O0\",\"width\":236}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=./main_trainer.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=./main_trainer\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-322537213286/training-job-1597937149/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"nccl\",\"batch-size\":1024,\"height\":137,\"lr\":0.0001,\"model_name\":\"resnet18\",\"num_epochs\":5,\"opt-level\":\"O0\",\"width\":236},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"training-job-1597937149\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-322537213286/training-job-1597937149/source/sourcedir.tar.gz\",\"module_name\":\"./main_trainer\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"./main_trainer.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"nccl\",\"--batch-size\",\"1024\",\"--height\",\"137\",\"--lr\",\"0.0001\",\"--model_name\",\"resnet18\",\"--num_epochs\",\"5\",\"--opt-level\",\"O0\",\"--width\",\"236\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_OPT-LEVEL=O0\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=resnet18\u001b[0m\n",
      "\u001b[34mSM_HP_WIDTH=236\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=nccl\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_HEIGHT=137\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python ./main_trainer.py --backend nccl --batch-size 1024 --height 137 --lr 0.0001 --model_name resnet18 --num_epochs 5 --opt-level O0 --width 236\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34margs.use_cuda : True , args.num_gpus : 4\u001b[0m\n",
      "\u001b[34mmain args : Namespace(apex=False, backend='nccl', batch_size=1024, channels_last=True, current_host='algo-1', data_dir='/opt/ml/input/data/training', device=device(type='cuda'), height=137, hosts=['algo-1'], keep_batchnorm_fp32=None, kwargs={'num_workers': 0, 'pin_memory': True}, log_interval=10, loss_scale=None, lr=0.0001, model_dir='/opt/ml/model', model_name='resnet18', num_epochs=5, num_folds=5, num_gpus=4, opt_level='O0', output_data_dir='/opt/ml/output/data', print_freq=10, prof=-1, seed=1, sync_bn=True, use_cuda=True, val_batch_size=200, vld_fold_idx=4, width=236)\u001b[0m\n",
      "\u001b[34mdist_init args : Namespace(apex=False, backend='nccl', batch_size=1024, channels_last=True, current_host='algo-1', data_dir='/opt/ml/input/data/training', device=device(type='cuda'), height=137, hosts=['algo-1'], keep_batchnorm_fp32=None, kwargs={'num_workers': 0, 'pin_memory': True}, log_interval=10, loss_scale=None, lr=0.0001, model_dir='/opt/ml/model', model_name='resnet18', num_epochs=5, num_folds=5, num_gpus=4, opt_level='O0', output_data_dir='/opt/ml/output/data', print_freq=10, prof=-1, seed=1, sync_bn=True, use_cuda=True, val_batch_size=200, vld_fold_idx=4, width=236)\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 4\u001b[0m\n",
      "\u001b[34m=> using pre-trained model 'resnet18'\u001b[0m\n",
      "\u001b[34m=> using pre-trained model 'resnet18'\u001b[0m\n",
      "\u001b[34m=> using pre-trained model 'resnet18'\u001b[0m\n",
      "\u001b[34m=> using pre-trained model 'resnet18'\u001b[0m\n",
      "\u001b[34mchannels_last : True\u001b[0m\n",
      "\u001b[34mUse GPU: 2 for training\u001b[0m\n",
      "\u001b[34mchannels_last : True\u001b[0m\n",
      "\u001b[34mUse GPU: 3 for training\u001b[0m\n",
      "\u001b[34mchannels_last : True\u001b[0m\n",
      "\u001b[34mUse GPU: 1 for training\u001b[0m\n",
      "\u001b[34mchannels_last : True\u001b[0m\n",
      "\u001b[34mUse GPU: 0 for training\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'nccl' backend on 4 nodes. Current host rank is 2. Number of gpus: 4\u001b[0m\n",
      "\u001b[34musing apex synced BN\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'nccl' backend on 4 nodes. Current host rank is 3. Number of gpus: 4\u001b[0m\n",
      "\u001b[34musing apex synced BN\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'nccl' backend on 4 nodes. Current host rank is 1. Number of gpus: 4\u001b[0m\n",
      "\u001b[34musing apex synced BN\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'nccl' backend on 4 nodes. Current host rank is 0. Number of gpus: 4\u001b[0m\n",
      "\u001b[34musing apex synced BN\u001b[0m\n",
      "\u001b[34mSelected optimization level O0:  Pure FP32 training.\n",
      "\u001b[0m\n",
      "\u001b[34mDefaults for this optimization level are:\u001b[0m\n",
      "\u001b[34menabled                : True\u001b[0m\n",
      "\u001b[34mopt_level              : O0\u001b[0m\n",
      "\u001b[34mcast_model_type        : torch.float32\u001b[0m\n",
      "\u001b[34mpatch_torch_functions  : False\u001b[0m\n",
      "\u001b[34mkeep_batchnorm_fp32    : None\u001b[0m\n",
      "\u001b[34mmaster_weights         : False\u001b[0m\n",
      "\u001b[34mloss_scale             : 1.0\u001b[0m\n",
      "\u001b[34mProcessing user overrides (additional kwargs that are not None)...\u001b[0m\n",
      "\u001b[34mAfter processing overrides, optimization options are:\u001b[0m\n",
      "\u001b[34menabled                : True\u001b[0m\n",
      "\u001b[34mopt_level              : O0\u001b[0m\n",
      "\u001b[34mcast_model_type        : torch.float32\u001b[0m\n",
      "\u001b[34mpatch_torch_functions  : False\u001b[0m\n",
      "\u001b[34mkeep_batchnorm_fp32    : None\u001b[0m\n",
      "\u001b[34mmaster_weights         : False\u001b[0m\n",
      "\u001b[34mloss_scale             : 1.0\u001b[0m\n",
      "\u001b[34mNCCL version 2.4.8+cuda10.1\u001b[0m\n",
      "\u001b[34m=== Getting Labels ===\u001b[0m\n",
      "\u001b[34m=== Getting Labels ===\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m=== Getting Labels ===\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m=== Getting Labels ===\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m=== Getting Images ===\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/training/train_image_data_0.feather', '/opt/ml/input/data/training/train_image_data_1.feather', '/opt/ml/input/data/training/train_image_data_2.feather', '/opt/ml/input/data/training/train_image_data_3.feather']\u001b[0m\n",
      "\u001b[34m=== Getting Images ===\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/training/train_image_data_0.feather', '/opt/ml/input/data/training/train_image_data_1.feather', '/opt/ml/input/data/training/train_image_data_2.feather', '/opt/ml/input/data/training/train_image_data_3.feather']\u001b[0m\n",
      "\u001b[34m=== Getting Images ===\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/training/train_image_data_0.feather', '/opt/ml/input/data/training/train_image_data_1.feather', '/opt/ml/input/data/training/train_image_data_2.feather', '/opt/ml/input/data/training/train_image_data_3.feather']\u001b[0m\n",
      "\u001b[34m=== Getting Images ===\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/training/train_image_data_0.feather', '/opt/ml/input/data/training/train_image_data_1.feather', '/opt/ml/input/data/training/train_image_data_2.feather', '/opt/ml/input/data/training/train_image_data_3.feather']\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet val data loader\u001b[0m\n",
      "\u001b[34mProcesses 40168/160672 (25%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10042/40168 (25%) of test data\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet val data loader\u001b[0m\n",
      "\u001b[34mProcesses 40168/160672 (25%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10042/40168 (25%) of test data\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet val data loader\u001b[0m\n",
      "\u001b[34mProcesses 40168/160672 (25%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10042/40168 (25%) of test data\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet val data loader\u001b[0m\n",
      "\u001b[34mProcesses 40168/160672 (25%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10042/40168 (25%) of test data\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.459 algo-1:149 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.459 algo-1:147 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.459 algo-1:149 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.459 algo-1:147 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.459 algo-1:149 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.459 algo-1:147 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.461 algo-1:149 INFO hook.py:364] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.461 algo-1:147 INFO hook.py:364] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.490 algo-1:148 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.491 algo-1:148 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.491 algo-1:148 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.492 algo-1:148 INFO hook.py:364] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.494 algo-1:146 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.494 algo-1:146 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.494 algo-1:146 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-08-20 15:31:41.496 algo-1:146 INFO hook.py:364] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 10/157] loss: 3.1255\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 10/157] loss: 3.1166\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 10/157] loss: 3.1294\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 10/157] loss: 3.1247\u001b[0m\n",
      "\u001b[34mEpoch: [1][10/157]  Time 3.302 (3.302)  Speed 310.094 (310.094)  Loss 2.6470284462 (2.6470)  Prec@1 38.843 (38.843)  Prec@5 61.841 (61.841)\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 20/157] loss: 2.6431\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 20/157] loss: 2.6376\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 20/157] loss: 2.6473\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 20/157] loss: 2.6441\u001b[0m\n",
      "\u001b[34mEpoch: [1][20/157]  Time 2.879 (3.091)  Speed 355.667 (331.321)  Loss 2.2967181206 (2.4719)  Prec@1 47.949 (43.396)  Prec@5 69.214 (65.527)\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 30/157] loss: 2.3758\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 30/157] loss: 2.3891\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 30/157] loss: 2.3688\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 30/157] loss: 2.3727\u001b[0m\n",
      "\u001b[34mEpoch: [1][30/157]  Time 2.919 (3.034)  Speed 350.777 (337.562)  Loss 2.1440057755 (2.3626)  Prec@1 56.567 (47.786)  Prec@5 80.371 (70.475)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Epoch 1 Batch 40/157] loss: 2.3550\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 40/157] loss: 2.3485\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 40/157] loss: 2.3570\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 40/157] loss: 2.3558\u001b[0m\n",
      "\u001b[34mEpoch: [1][40/157]  Time 2.890 (2.998)  Speed 354.280 (341.592)  Loss 2.8432884216 (2.4828)  Prec@1 29.736 (43.274)  Prec@5 58.496 (67.480)\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 50/157] loss: 1.7249\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 50/157] loss: 1.6832\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 50/157] loss: 1.7055\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 50/157] loss: 1.7089\u001b[0m\n",
      "\u001b[34mEpoch: [1][50/157]  Time 2.866 (2.971)  Speed 357.242 (344.611)  Loss 1.6157498360 (2.3094)  Prec@1 65.015 (47.622)  Prec@5 89.404 (71.865)\u001b[0m\n",
      "\u001b[34mEpoch    55: reducing learning rate of group 0 to 2.0000e-04.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 60/157] loss: 1.9123\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 60/157] loss: 1.9082\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 60/157] loss: 1.9087\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 60/157] loss: 1.9225\u001b[0m\n",
      "\u001b[34mEpoch: [1][60/157]  Time 2.888 (2.958)  Speed 354.604 (346.237)  Loss 1.2435557842 (2.1317)  Prec@1 72.168 (51.713)  Prec@5 92.407 (75.289)\u001b[0m\n",
      "\u001b[34mEpoch    63: reducing learning rate of group 0 to 2.0000e-04.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 70/157] loss: 1.8854\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 70/157] loss: 1.8843\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 70/157] loss: 1.8760\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 70/157] loss: 1.8592\u001b[0m\n",
      "\u001b[34mEpoch: [1][70/157]  Time 2.951 (2.957)  Speed 347.034 (346.351)  Loss 2.6518247128 (2.2060)  Prec@1 40.234 (50.073)  Prec@5 67.920 (74.236)\u001b[0m\n",
      "\u001b[34mEpoch    75: reducing learning rate of group 0 to 2.0000e-04.\u001b[0m\n",
      "\u001b[34mEpoch    78: reducing learning rate of group 0 to 1.0000e-04.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 80/157] loss: 1.4544\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 80/157] loss: 1.4416\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 80/157] loss: 1.3708\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 80/157] loss: 1.4172\u001b[0m\n",
      "\u001b[34mEpoch: [1][80/157]  Time 2.929 (2.953)  Speed 349.660 (346.761)  Loss 1.0460252762 (2.0610)  Prec@1 76.465 (53.372)  Prec@5 94.116 (76.721)\u001b[0m\n",
      "\u001b[34mEpoch    85: reducing learning rate of group 0 to 2.0000e-04.\u001b[0m\n",
      "\u001b[34mEpoch    85: reducing learning rate of group 0 to 5.0000e-05.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 90/157] loss: 1.4402\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 90/157] loss: 1.3420\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 90/157] loss: 1.4268\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 90/157] loss: 1.3668\u001b[0m\n",
      "\u001b[34mEpoch: [1][90/157]  Time 2.843 (2.941)  Speed 360.225 (348.207)  Loss 2.9415056705 (2.1589)  Prec@1 27.344 (50.480)  Prec@5 59.204 (74.775)\u001b[0m\n",
      "\u001b[34mEpoch    92: reducing learning rate of group 0 to 1.0000e-04.\u001b[0m\n",
      "\u001b[34mEpoch    92: reducing learning rate of group 0 to 2.5000e-05.\u001b[0m\n",
      "\u001b[34mEpoch    95: reducing learning rate of group 0 to 1.0000e-04.\u001b[0m\n",
      "\u001b[34mEpoch    98: reducing learning rate of group 0 to 5.0000e-05.\u001b[0m\n",
      "\u001b[34mEpoch    99: reducing learning rate of group 0 to 1.0000e-04.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 100/157] loss: 1.5496\u001b[0m\n",
      "\u001b[34mEpoch   100: reducing learning rate of group 0 to 1.2500e-05.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 100/157] loss: 1.5252\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 100/157] loss: 1.5964\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 100/157] loss: 1.6033\u001b[0m\n",
      "\u001b[34mEpoch: [1][100/157]  Time 2.881 (2.935)  Speed 355.456 (348.919)  Loss 2.4276990891 (2.1857)  Prec@1 51.489 (50.581)  Prec@5 79.272 (75.225)\u001b[0m\n",
      "\u001b[34mEpoch   101: reducing learning rate of group 0 to 5.0000e-05.\u001b[0m\n",
      "\u001b[34mEpoch   105: reducing learning rate of group 0 to 5.0000e-05.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 110/157] loss: 1.2782\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 110/157] loss: 1.3589\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 110/157] loss: 1.2778\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 110/157] loss: 1.2516\u001b[0m\n",
      "\u001b[34mEpoch: [1][110/157]  Time 2.945 (2.936)  Speed 347.668 (348.805)  Loss 0.9357706904 (2.0721)  Prec@1 78.613 (53.129)  Prec@5 94.775 (77.002)\u001b[0m\n",
      "\u001b[34mEpoch   111: reducing learning rate of group 0 to 2.5000e-05.\u001b[0m\n",
      "\u001b[34mEpoch   111: reducing learning rate of group 0 to 6.2500e-06.\u001b[0m\n",
      "\u001b[34mEpoch   111: reducing learning rate of group 0 to 2.5000e-05.\u001b[0m\n",
      "\u001b[34mEpoch   112: reducing learning rate of group 0 to 2.5000e-05.\u001b[0m\n",
      "\u001b[34mEpoch   118: reducing learning rate of group 0 to 1.2500e-05.\u001b[0m\n",
      "\u001b[34mEpoch   119: reducing learning rate of group 0 to 1.2500e-05.\u001b[0m\n",
      "\u001b[34mEpoch   119: reducing learning rate of group 0 to 1.2500e-05.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 120/157] loss: 1.6604\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 120/157] loss: 1.7260\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 120/157] loss: 1.6860\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 120/157] loss: 1.6699\u001b[0m\n",
      "\u001b[34mEpoch: [1][120/157]  Time 2.914 (2.934)  Speed 351.357 (349.016)  Loss 2.6136441231 (2.1172)  Prec@1 21.289 (50.476)  Prec@5 48.706 (74.644)\u001b[0m\n",
      "\u001b[34mEpoch   121: reducing learning rate of group 0 to 3.1250e-06.\u001b[0m\n",
      "\u001b[34mEpoch   124: reducing learning rate of group 0 to 6.2500e-06.\u001b[0m\n",
      "\u001b[34mEpoch   125: reducing learning rate of group 0 to 6.2500e-06.\u001b[0m\n",
      "\u001b[34mEpoch   125: reducing learning rate of group 0 to 6.2500e-06.\u001b[0m\n",
      "\u001b[34mEpoch   127: reducing learning rate of group 0 to 1.5625e-06.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 130/157] loss: 1.7126\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 130/157] loss: 1.7107\u001b[0m\n",
      "\u001b[34mEpoch   130: reducing learning rate of group 0 to 3.1250e-06.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 130/157] loss: 1.7791\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 130/157] loss: 1.7735\u001b[0m\n",
      "\u001b[34mEpoch: [1][130/157]  Time 2.927 (2.933)  Speed 349.885 (349.083)  Loss 0.9031767249 (2.0238)  Prec@1 79.346 (52.697)  Prec@5 95.190 (76.224)\u001b[0m\n",
      "\u001b[34mEpoch   131: reducing learning rate of group 0 to 3.1250e-06.\u001b[0m\n",
      "\u001b[34mEpoch   133: reducing learning rate of group 0 to 7.8125e-07.\u001b[0m\n",
      "\u001b[34mEpoch   133: reducing learning rate of group 0 to 3.1250e-06.\u001b[0m\n",
      "\u001b[34mEpoch   136: reducing learning rate of group 0 to 1.5625e-06.\u001b[0m\n",
      "\u001b[34mEpoch   137: reducing learning rate of group 0 to 1.5625e-06.\u001b[0m\n",
      "\u001b[34mEpoch   139: reducing learning rate of group 0 to 3.9063e-07.\u001b[0m\n",
      "\u001b[34mEpoch   139: reducing learning rate of group 0 to 1.5625e-06.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 140/157] loss: 1.6457\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 140/157] loss: 1.6606\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 140/157] loss: 1.6777\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 140/157] loss: 1.7411\u001b[0m\n",
      "\u001b[34mEpoch: [1][140/157]  Time 2.973 (2.936)  Speed 344.468 (348.749)  Loss 0.8599666357 (1.9407)  Prec@1 82.251 (54.808)  Prec@5 95.947 (77.633)\u001b[0m\n",
      "\u001b[34mEpoch   142: reducing learning rate of group 0 to 7.8125e-07.\u001b[0m\n",
      "\u001b[34mEpoch   145: reducing learning rate of group 0 to 7.8125e-07.\u001b[0m\n",
      "\u001b[34mEpoch   149: reducing learning rate of group 0 to 1.9531e-07.\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 150/157] loss: 1.1257\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 150/157] loss: 1.2244\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 150/157] loss: 1.1315\u001b[0m\n",
      "\u001b[34m[Epoch 1 Batch 150/157] loss: 1.1864\u001b[0m\n",
      "\u001b[34mEpoch: [1][150/157]  Time 2.960 (2.938)  Speed 346.004 (348.565)  Loss 1.0124679804 (1.8788)  Prec@1 82.544 (56.657)  Prec@5 96.729 (78.906)\u001b[0m\n",
      "\u001b[34mEpoch   151: reducing learning rate of group 0 to 3.9063e-07.\u001b[0m\n",
      "\u001b[34mEpoch   153: reducing learning rate of group 0 to 7.8125e-07.\u001b[0m\n",
      "\u001b[34mEpoch   153: reducing learning rate of group 0 to 3.9063e-07.\u001b[0m\n",
      "\u001b[34mEpoch   155: reducing learning rate of group 0 to 9.7656e-08.\u001b[0m\n",
      "\u001b[34mTest: [10/51]  Time 0.918 (0.890)  Speed 1115.572 (1150.590)  val_Loss 1.4197 (1.4366)  val_Prec 85.312 (84.144)  val_Prec@5 97.688 (97.297)\u001b[0m\n",
      "\u001b[34mTest: [20/51]  Time 0.862 (0.883)  Speed 1187.404 (1160.332)  val_Loss 1.4161 (1.4319)  val_Prec 86.406 (84.653)  val_Prec@5 97.219 (97.273)\u001b[0m\n",
      "\u001b[34mTest: [30/51]  Time 0.863 (0.875)  Speed 1186.909 (1170.893)  val_Loss 1.4418 (1.4361)  val_Prec 84.344 (84.513)  val_Prec@5 97.250 (97.258)\u001b[0m\n",
      "\u001b[34mTest: [40/51]  Time 0.886 (0.873)  Speed 1155.615 (1173.089)  val_Loss 1.4156 (1.4338)  val_Prec 85.594 (84.549)  val_Prec@5 97.500 (97.264)\u001b[0m\n",
      "\u001b[34mTest: [50/51]  Time 0.858 (0.872)  Speed 1193.966 (1174.258)  val_Loss 1.4016 (1.4311)  val_Prec 85.656 (84.650)  val_Prec@5 97.562 (97.288)\n",
      "  Prec@1 84.643 Prec@5 97.285\n",
      "  Prec@1 84.643 Prec@5 97.285\n",
      "  Prec@1 84.643 Prec@5 97.285\u001b[0m\n",
      "\u001b[34m[Epoch 1] trn_loss: 1.8558, vld_loss: 1.5319, score: 0.6015, score_g: 0.4779, score_v:0.8252, score_c: 0.6248\n",
      "  Prec@1 84.643 Prec@5 97.285\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mEpoch   159: reducing learning rate of group 0 to 3.9063e-07.\u001b[0m\n",
      "\u001b[34mEpoch   159: reducing learning rate of group 0 to 1.9531e-07.\u001b[0m\n",
      "\u001b[34mEpoch   160: reducing learning rate of group 0 to 1.9531e-07.\u001b[0m\n",
      "\u001b[34mEpoch   161: reducing learning rate of group 0 to 4.8828e-08.\u001b[0m\n",
      "\u001b[34mEpoch   165: reducing learning rate of group 0 to 1.9531e-07.\u001b[0m\n",
      "\u001b[34mEpoch   165: reducing learning rate of group 0 to 9.7656e-08.\u001b[0m\n",
      "\u001b[34mEpoch   166: reducing learning rate of group 0 to 9.7656e-08.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Epoch 2 Batch 10/157] loss: 1.7387\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 10/157] loss: 1.7066\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 10/157] loss: 1.7363\u001b[0m\n",
      "\u001b[34mEpoch   167: reducing learning rate of group 0 to 2.4414e-08.\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 10/157] loss: 1.8373\u001b[0m\n",
      "\u001b[34mEpoch: [2][10/157]  Time 2.908 (2.908)  Speed 352.108 (352.108)  Loss 0.8650103211 (0.8650)  Prec@1 81.763 (81.763)  Prec@5 96.240 (96.240)\u001b[0m\n",
      "\u001b[34mEpoch   171: reducing learning rate of group 0 to 4.8828e-08.\u001b[0m\n",
      "\u001b[34mEpoch   172: reducing learning rate of group 0 to 4.8828e-08.\u001b[0m\n",
      "\u001b[34mEpoch   173: reducing learning rate of group 0 to 1.2207e-08.\u001b[0m\n",
      "\u001b[34mEpoch   175: reducing learning rate of group 0 to 9.7656e-08.\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 20/157] loss: 1.3963\u001b[0m\n",
      "\u001b[34mEpoch   177: reducing learning rate of group 0 to 2.4414e-08.\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 20/157] loss: 1.4029\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 20/157] loss: 1.4353\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 20/157] loss: 1.4653\u001b[0m\n",
      "\u001b[34mEpoch: [2][20/157]  Time 2.887 (2.898)  Speed 354.672 (353.385)  Loss 0.8748606443 (0.8699)  Prec@1 80.762 (81.262)  Prec@5 95.630 (95.935)\u001b[0m\n",
      "\u001b[34mEpoch   178: reducing learning rate of group 0 to 2.4414e-08.\u001b[0m\n",
      "\u001b[34mEpoch   181: reducing learning rate of group 0 to 4.8828e-08.\u001b[0m\n",
      "\u001b[34mEpoch   183: reducing learning rate of group 0 to 1.2207e-08.\u001b[0m\n",
      "\u001b[34mEpoch   184: reducing learning rate of group 0 to 1.2207e-08.\u001b[0m\n",
      "\u001b[34mEpoch   187: reducing learning rate of group 0 to 2.4414e-08.\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 30/157] loss: 1.7478\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 30/157] loss: 1.7401\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 30/157] loss: 1.8600\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 30/157] loss: 1.7538\u001b[0m\n",
      "\u001b[34mEpoch: [2][30/157]  Time 2.901 (2.899)  Speed 352.949 (353.240)  Loss 0.8259714842 (0.8553)  Prec@1 82.593 (81.706)  Prec@5 96.753 (96.208)\u001b[0m\n",
      "\u001b[34mEpoch   193: reducing learning rate of group 0 to 1.2207e-08.\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 40/157] loss: 1.5761\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 40/157] loss: 1.5727\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 40/157] loss: 1.6096\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 40/157] loss: 1.6670\u001b[0m\n",
      "\u001b[34mEpoch: [2][40/157]  Time 2.870 (2.892)  Speed 356.835 (354.132)  Loss 0.8401118517 (0.8515)  Prec@1 81.470 (81.647)  Prec@5 96.045 (96.167)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 50/157] loss: 2.0650\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 50/157] loss: 2.0815\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 50/157] loss: 2.1388\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 50/157] loss: 2.1767\u001b[0m\n",
      "\u001b[34mEpoch: [2][50/157]  Time 2.802 (2.874)  Speed 365.404 (356.330)  Loss 2.9139261246 (1.2640)  Prec@1 26.685 (70.654)  Prec@5 54.932 (87.920)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 60/157] loss: 1.6392\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 60/157] loss: 1.6405\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 60/157] loss: 1.6725\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 60/157] loss: 1.7368\u001b[0m\n",
      "\u001b[34mEpoch: [2][60/157]  Time 2.966 (2.889)  Speed 345.296 (354.442)  Loss 2.2374649048 (1.4262)  Prec@1 57.031 (68.384)  Prec@5 86.353 (87.659)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 70/157] loss: 1.3416\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 70/157] loss: 1.3981\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 70/157] loss: 1.3593\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 70/157] loss: 1.4692\u001b[0m\n",
      "\u001b[34mEpoch: [2][70/157]  Time 2.922 (2.894)  Speed 350.416 (353.862)  Loss 1.7575052977 (1.4736)  Prec@1 72.290 (68.942)  Prec@5 93.701 (88.522)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 80/157] loss: 1.1941\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 80/157] loss: 1.1925\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 80/157] loss: 1.2999\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 80/157] loss: 1.2447\u001b[0m\n",
      "\u001b[34mEpoch: [2][80/157]  Time 2.825 (2.885)  Speed 362.439 (354.911)  Loss 0.8323432207 (1.3934)  Prec@1 81.641 (70.529)  Prec@5 96.558 (89.526)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 90/157] loss: 1.5950\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 90/157] loss: 1.5721\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 90/157] loss: 1.6287\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 90/157] loss: 1.6921\u001b[0m\n",
      "\u001b[34mEpoch: [2][90/157]  Time 2.917 (2.889)  Speed 350.996 (354.472)  Loss 0.8402253389 (1.3319)  Prec@1 82.593 (71.870)  Prec@5 95.850 (90.229)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 100/157] loss: 1.7176\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 100/157] loss: 1.7370\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 100/157] loss: 1.8414\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 100/157] loss: 1.7728\u001b[0m\n",
      "\u001b[34mEpoch: [2][100/157]  Time 3.032 (2.903)  Speed 337.777 (352.729)  Loss 0.8577031493 (1.2845)  Prec@1 81.519 (72.834)  Prec@5 95.532 (90.759)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 110/157] loss: 1.8448\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 110/157] loss: 1.9420\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 110/157] loss: 1.8802\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 110/157] loss: 1.8625\u001b[0m\n",
      "\u001b[34mEpoch: [2][110/157]  Time 2.858 (2.899)  Speed 358.316 (353.229)  Loss 2.8009448051 (1.4224)  Prec@1 35.425 (69.434)  Prec@5 65.894 (88.499)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 120/157] loss: 1.7924\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 120/157] loss: 1.7746\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 120/157] loss: 1.9040\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 120/157] loss: 1.8122\u001b[0m\n",
      "\u001b[34mEpoch: [2][120/157]  Time 2.973 (2.905)  Speed 344.399 (352.476)  Loss 1.4818756580 (1.4273)  Prec@1 78.174 (70.162)  Prec@5 95.508 (89.083)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 130/157] loss: 1.6963\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 130/157] loss: 1.6993\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 130/157] loss: 1.7310\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 130/157] loss: 1.8035\u001b[0m\n",
      "\u001b[34mEpoch: [2][130/157]  Time 2.968 (2.910)  Speed 344.999 (351.890)  Loss 2.0342450142 (1.4740)  Prec@1 52.148 (68.776)  Prec@5 79.688 (88.360)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 140/157] loss: 1.3270\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 140/157] loss: 1.4494\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 140/157] loss: 1.3187\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 140/157] loss: 1.3753\u001b[0m\n",
      "\u001b[34mEpoch: [2][140/157]  Time 2.800 (2.902)  Speed 365.706 (352.842)  Loss 0.8495431542 (1.4294)  Prec@1 81.616 (69.693)  Prec@5 96.387 (88.933)\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 150/157] loss: 1.8511\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 150/157] loss: 1.9189\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 150/157] loss: 1.8628\u001b[0m\n",
      "\u001b[34m[Epoch 2 Batch 150/157] loss: 1.8044\u001b[0m\n",
      "\u001b[34mEpoch: [2][150/157]  Time 2.903 (2.902)  Speed 352.736 (352.835)  Loss 0.8858721256 (1.3932)  Prec@1 80.151 (70.391)  Prec@5 95.312 (89.359)\u001b[0m\n",
      "\u001b[34mTest: [10/51]  Time 0.925 (0.889)  Speed 1106.806 (1152.192)  val_Loss 1.4194 (1.4357)  val_Prec 85.438 (84.222)  val_Prec@5 97.688 (97.328)\u001b[0m\n",
      "\u001b[34mTest: [20/51]  Time 0.947 (0.878)  Speed 1081.687 (1166.325)  val_Loss 1.4155 (1.4312)  val_Prec 86.312 (84.666)  val_Prec@5 97.281 (97.300)\u001b[0m\n",
      "\u001b[34mTest: [30/51]  Time 0.875 (0.880)  Speed 1170.054 (1164.202)  val_Loss 1.4409 (1.4354)  val_Prec 84.406 (84.549)  val_Prec@5 97.125 (97.286)\u001b[0m\n",
      "\u001b[34mTest: [40/51]  Time 0.848 (0.875)  Speed 1207.883 (1169.736)  val_Loss 1.4150 (1.4330)  val_Prec 85.844 (84.603)  val_Prec@5 97.500 (97.284)\u001b[0m\n",
      "\u001b[34mTest: [50/51]  Time 1.135 (0.884)  Speed 901.879 (1158.258)  val_Loss 1.4016 (1.4304)  val_Prec 85.562 (84.694)  val_Prec@5 97.500 (97.307)\n",
      "  Prec@1 84.689 Prec@5 97.303\n",
      "  Prec@1 84.689 Prec@5 97.303\u001b[0m\n",
      "\u001b[34m[Epoch 2] trn_loss: 1.7219, vld_loss: 1.5311, score: 0.6015, score_g: 0.4784, score_v:0.8255, score_c: 0.6236\n",
      "  Prec@1 84.689 Prec@5 97.303\n",
      "  Prec@1 84.689 Prec@5 97.303\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 10/157] loss: 1.8988\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 10/157] loss: 1.8573\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 10/157] loss: 1.9595\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 10/157] loss: 1.9067\u001b[0m\n",
      "\u001b[34mEpoch: [3][10/157]  Time 2.794 (2.794)  Speed 366.495 (366.495)  Loss 2.3090825081 (2.3091)  Prec@1 54.907 (54.907)  Prec@5 81.934 (81.934)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 20/157] loss: 1.5239\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 20/157] loss: 1.5120\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 20/157] loss: 1.5935\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 20/157] loss: 1.5484\u001b[0m\n",
      "\u001b[34mEpoch: [3][20/157]  Time 2.985 (2.889)  Speed 343.081 (354.401)  Loss 2.8089289665 (2.5590)  Prec@1 26.782 (40.845)  Prec@5 57.251 (69.592)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 30/157] loss: 1.5234\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 30/157] loss: 1.4868\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 30/157] loss: 1.5954\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 30/157] loss: 1.5419\u001b[0m\n",
      "\u001b[34mEpoch: [3][30/157]  Time 2.931 (2.903)  Speed 349.312 (352.688)  Loss 0.8705536127 (1.9962)  Prec@1 80.908 (54.199)  Prec@5 95.947 (78.377)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 40/157] loss: 1.8306\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 40/157] loss: 1.9321\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 40/157] loss: 1.8267\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 40/157] loss: 1.8666\u001b[0m\n",
      "\u001b[34mEpoch: [3][40/157]  Time 3.009 (2.930)  Speed 340.306 (349.509)  Loss 2.7833414078 (2.1930)  Prec@1 32.593 (48.798)  Prec@5 62.915 (74.512)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 50/157] loss: 1.4492\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 50/157] loss: 1.4299\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 50/157] loss: 1.4897\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 50/157] loss: 1.5716\u001b[0m\n",
      "\u001b[34mEpoch: [3][50/157]  Time 2.836 (2.911)  Speed 361.115 (351.770)  Loss 0.8746135235 (1.9293)  Prec@1 80.420 (55.122)  Prec@5 96.069 (78.823)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[Epoch 3 Batch 60/157] loss: 1.6059\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 60/157] loss: 1.6149\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 60/157] loss: 1.6469\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 60/157] loss: 1.7174\u001b[0m\n",
      "\u001b[34mEpoch: [3][60/157]  Time 2.845 (2.900)  Speed 359.878 (353.096)  Loss 0.8755669594 (1.7537)  Prec@1 81.445 (59.509)  Prec@5 96.045 (81.694)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 70/157] loss: 1.6976\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 70/157] loss: 1.6742\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 70/157] loss: 1.7460\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 70/157] loss: 1.7758\u001b[0m\n",
      "\u001b[34mEpoch: [3][70/157]  Time 2.890 (2.899)  Speed 354.276 (353.264)  Loss 2.7622807026 (1.8978)  Prec@1 23.950 (54.429)  Prec@5 51.782 (77.420)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 80/157] loss: 1.3236\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 80/157] loss: 1.3106\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 80/157] loss: 1.4158\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 80/157] loss: 1.3933\u001b[0m\n",
      "\u001b[34mEpoch: [3][80/157]  Time 2.965 (2.907)  Speed 345.334 (352.253)  Loss 0.8612000942 (1.7682)  Prec@1 81.006 (57.751)  Prec@5 95.874 (79.727)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 90/157] loss: 1.3139\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 90/157] loss: 1.3577\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 90/157] loss: 1.4021\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 90/157] loss: 1.4144\u001b[0m\n",
      "\u001b[34mEpoch: [3][90/157]  Time 2.937 (2.910)  Speed 348.635 (351.847)  Loss 0.8581939340 (1.6671)  Prec@1 81.470 (60.387)  Prec@5 96.167 (81.554)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 100/157] loss: 1.5068\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 100/157] loss: 1.5145\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 100/157] loss: 1.5833\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 100/157] loss: 1.5240\u001b[0m\n",
      "\u001b[34mEpoch: [3][100/157]  Time 2.873 (2.907)  Speed 356.472 (352.304)  Loss 1.7214169502 (1.6725)  Prec@1 70.850 (61.433)  Prec@5 91.992 (82.598)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 110/157] loss: 1.8409\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 110/157] loss: 1.8191\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 110/157] loss: 1.8429\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 110/157] loss: 1.8987\u001b[0m\n",
      "\u001b[34mEpoch: [3][110/157]  Time 2.865 (2.903)  Speed 357.470 (352.768)  Loss 1.4051558971 (1.6482)  Prec@1 78.564 (62.991)  Prec@5 94.946 (83.720)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 120/157] loss: 1.4017\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 120/157] loss: 1.4186\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 120/157] loss: 1.3793\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 120/157] loss: 1.5002\u001b[0m\n",
      "\u001b[34mEpoch: [3][120/157]  Time 2.908 (2.903)  Speed 352.121 (352.714)  Loss 0.8858628869 (1.5847)  Prec@1 80.713 (64.467)  Prec@5 95.239 (84.680)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 130/157] loss: 1.5388\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 130/157] loss: 1.5281\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 130/157] loss: 1.5701\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 130/157] loss: 1.6414\u001b[0m\n",
      "\u001b[34mEpoch: [3][130/157]  Time 2.950 (2.907)  Speed 347.089 (352.275)  Loss 2.5192883015 (1.6566)  Prec@1 18.335 (60.919)  Prec@5 46.777 (81.765)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 140/157] loss: 1.4626\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 140/157] loss: 1.4658\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 140/157] loss: 1.5773\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 140/157] loss: 1.5084\u001b[0m\n",
      "\u001b[34mEpoch: [3][140/157]  Time 2.875 (2.905)  Speed 356.130 (352.547)  Loss 0.8711449504 (1.6005)  Prec@1 81.323 (62.376)  Prec@5 95.435 (82.741)\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 150/157] loss: 1.4191\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 150/157] loss: 1.4636\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 150/157] loss: 1.4170\u001b[0m\n",
      "\u001b[34m[Epoch 3 Batch 150/157] loss: 1.5252\u001b[0m\n",
      "\u001b[34mEpoch: [3][150/157]  Time 2.774 (2.896)  Speed 369.152 (353.608)  Loss 0.8778619766 (1.5523)  Prec@1 81.665 (63.662)  Prec@5 95.532 (83.594)\u001b[0m\n",
      "\u001b[34mTest: [10/51]  Time 0.926 (0.877)  Speed 1105.426 (1168.114)  val_Loss 1.4211 (1.4378)  val_Prec 85.281 (84.181)  val_Prec@5 97.625 (97.266)\u001b[0m\n",
      "\u001b[34mTest: [20/51]  Time 0.871 (0.874)  Speed 1176.044 (1171.935)  val_Loss 1.4183 (1.4334)  val_Prec 86.406 (84.666)  val_Prec@5 97.281 (97.256)\u001b[0m\n",
      "\u001b[34mTest: [30/51]  Time 0.908 (0.877)  Speed 1128.020 (1167.880)  val_Loss 1.4431 (1.4376)  val_Prec 84.469 (84.542)  val_Prec@5 97.062 (97.247)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session.logs_for_job(estimator.latest_training_job.name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = estimator.model_data.replace('model.tar.gz', '')\n",
    "print(artifacts_dir)\n",
    "!aws s3 ls --human-readable {artifacts_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model'\n",
    "output_dir = './output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $model_dir\n",
    "!rm -rf $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json , os\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "!aws s3 cp {artifacts_dir}model.tar.gz {model_dir}/model.tar.gz\n",
    "!tar -xzf {model_dir}/model.tar.gz -C {model_dir}\n",
    "!aws s3 cp {artifacts_dir}output.tar.gz {output_dir}/output.tar.gz\n",
    "!tar -xzf {output_dir}/output.tar.gz -C {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json , os\n",
    "\n",
    "with open(os.path.join(output_dir, 'model_history.p'), \"r\") as f:\n",
    "    model_history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history['epoch'], model_history['losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(history): \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharex=True)\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(history['epoch'], history['losses'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_losses'], label='validation')\n",
    "    ax.set(\n",
    "        title='model loss',\n",
    "        ylabel='loss',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.plot(history['epoch'], history['batch_time'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_batch_time'], label='validation')\n",
    "    ax.set(\n",
    "        title='model batch_time',\n",
    "        ylabel='batch_time',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    \n",
    "    ax = axes[2]\n",
    "    ax.plot(history['epoch'], history['top1'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_top1'], label='validation')\n",
    "    ax.set(\n",
    "        title='top1 accuracy',\n",
    "        ylabel='accuracy',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[3]\n",
    "    ax.plot(history['epoch'], history['top5'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_top5'], label='validation')\n",
    "    ax.set(\n",
    "        title='top5 accuracy',\n",
    "        ylabel='accuracy',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plot_training_curves(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store hyperparameters model_dir output_dir artifacts_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
